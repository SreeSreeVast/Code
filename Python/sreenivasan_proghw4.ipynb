{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c15c0c",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Use the Jacobi Method to solve the following sparse system for $n = 100$ and $n = 10000$. Use the stopping criterion that the infinity norm of the difference between the iterate and true solution is less than $10^{-6}$. The correct solution is $[1,\\dots,1]$. Report the number of steps needed and the backward error. The system is\n",
    "\\begin{equation*}\n",
    "\\left[\\begin{array}{rcccc}{3} & {-1} & {} & {} & {} \\\\ {-1} & {3} & {-1} & {} & {} \\\\ {} & {\\ddots} & {\\ddots} & {\\ddots} & {} \\\\ {} & {} & {-1} & {3} & {-1} \\\\ {} & {} & {} & {-1} & {3}\\end{array}\\right]\\left[\\begin{array}{c}{x_{1}} \\\\ {\\vdots} \\\\ {x_{n}}\\end{array}\\right]=\\left[\\begin{array}{c}{2} \\\\ {1} \\\\ {\\vdots} \\\\ {1} \\\\ {2}\\end{array}\\right]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "499199e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=100\n",
      "# of Steps -  35\n",
      "Backward error -  6.867832083035097e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Jacobi method\n",
    "def jacobi(A, b, x_0, k):\n",
    "    \"\"\"\n",
    "    Perform k steps of Jacobi method\n",
    "    A: the matrix\n",
    "    b: the right-hand-side\n",
    "    x_0: initial guess x0\n",
    "    k: number of steps\n",
    "    \"\"\"\n",
    "    d = np.diag(A)\n",
    "    r  = A-np.diag(d)\n",
    "    # Initialize the solution vector\n",
    "    x = x_0.copy()\n",
    "    for j in range(k):\n",
    "        x = (b-np.dot(r,x))/d\n",
    "        \n",
    "    return x\n",
    "\n",
    "def matrix(n):\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        A[i, i] = 3\n",
    "        if i < n-1:\n",
    "            A[i, i+1] = -1\n",
    "            A[i+1, i] = -1\n",
    "\n",
    "    return A\n",
    "# n = 100\n",
    "n = 100\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "b[0]=2\n",
    "b[-1]=2\n",
    "x_0 = np.zeros(n)\n",
    "x_correct = np.ones(n)\n",
    "#steps counter\n",
    "i = 0\n",
    "while True:\n",
    "    x_0 = jacobi(A, b, x_0,1)\n",
    "    i += 1    \n",
    "    forward_error = abs(x_0 - x_correct).max()\n",
    "    if forward_error <  1e-6:\n",
    "        break\n",
    "backward_error = abs(A.dot(x_0) - b).max()\n",
    "print(\"n=100\")\n",
    "print(\"# of Steps - \", i)\n",
    "print(\"Backward error - \" , backward_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a30488dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=10000\n",
      "# of Steps -  35\n",
      "Backward error - 6.867832083035097e-07\n"
     ]
    }
   ],
   "source": [
    "#n=10000\n",
    "n = 10000\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "b[0]=2\n",
    "b[-1]=2\n",
    "x_0 = np.zeros(n)\n",
    "x_correct = np.ones(n)\n",
    "#steps counter\n",
    "i = 0\n",
    "while True:\n",
    "    x_0 = jacobi(A, b, x_0,1)\n",
    "    i += 1    \n",
    "    forward_error = abs(x_0 - x_correct).max()\n",
    "    if forward_error <  1e-6:\n",
    "        break\n",
    "\n",
    "backward_error = abs(A.dot(x_0) - b).max()\n",
    "print(\"n=10000\")\n",
    "print(\"# of Steps - \", i)\n",
    "print(\"Backward error -\", backward_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc855125",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "Carry out the steps of Problem 1 with $n = 100$ for \n",
    "\n",
    "(a) Gaussâ€“Seidel Method and\n",
    "\n",
    "(b) SOR with $\\omega = 1.2$.\n",
    "\n",
    "Which one converges faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65c656a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss-Siedel\n",
      "# of Steps -  20\n",
      "Backward error -  9.564705893971848e-07\n"
     ]
    }
   ],
   "source": [
    "# Gauss-Seidel method\n",
    "def Gauss_Seidel(A, b, x_0, k):\n",
    "    \"\"\"\n",
    "    Run k steps of Gauss_Seidel method\n",
    "    A: the matrix\n",
    "    b: the right-hand-side\n",
    "    x_0: initial guess x0\n",
    "    k: the number of steps\n",
    "    \"\"\" \n",
    "    # Get the size of the system\n",
    "    n = A.shape[0]\n",
    "    # Initialize the solution vector\n",
    "    x = x_0.copy()\n",
    "    \n",
    "    for l in range(k):\n",
    "        for i in range(n):\n",
    "            sum = 0.\n",
    "            for j in range(n):            \n",
    "                if i != j:\n",
    "                    sum += A[i,j]*x[j]\n",
    "            x[i] = (b[i]-sum)/A[i,i]   \n",
    "    return x\n",
    "\n",
    "#n=100\n",
    "n = 100\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "b[0]=2\n",
    "b[-1]=2\n",
    "x_0 = np.zeros(n)\n",
    "x_correct = np.ones(n)\n",
    "#steps counter\n",
    "i = 0\n",
    "while True:\n",
    "    x_0 = Gauss_Seidel(A, b, x_0,1)\n",
    "    i += 1    \n",
    "    forward_error = abs(x_0 - x_correct).max()\n",
    "    if forward_error <  1e-6:\n",
    "        break\n",
    "\n",
    "backward_error = abs(A.dot(x_0) - b).max()\n",
    "#GAUS\n",
    "print (\"Gauss-Siedel\")\n",
    "print(\"# of Steps - \", i)\n",
    "print(\"Backward error - \", backward_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eee3f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOR\n",
      "# of Steps -  16\n",
      "Backward error -  1.5515907683116836e-06\n"
     ]
    }
   ],
   "source": [
    "# SOR method\n",
    "def SOR(A, b, x_0, omega, k):\n",
    "    \"\"\"\n",
    "    Run k steps of the SOR method\n",
    "    A: the matrix\n",
    "    b: the right-hand-side\n",
    "    x_0: initial guess x0\n",
    "    omega: the relaxation parameter\n",
    "    k: the number of steps\n",
    "    \"\"\" \n",
    "    # Get the size of the system\n",
    "    n = A.shape[0]\n",
    "    # Initialize the solution vector\n",
    "    x = x_0.copy()\n",
    "    \n",
    "    for l in range(k):\n",
    "        for i in range(n):\n",
    "            sum = 0.\n",
    "            for j in range(n):            \n",
    "                if i != j:\n",
    "                    sum += A[i,j]*x[j]\n",
    "            x[i] = omega*(b[i]-sum)/A[i,i] + (1.-omega)*x[i]   \n",
    "    return x\n",
    "#n=100\n",
    "n = 100\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "b[0], b[-1] = 2, 2\n",
    "x_0 = np.zeros(n)\n",
    "x_correct = np.ones(n)\n",
    "#find steps\n",
    "i = 0\n",
    "while True:\n",
    "    x_0 = SOR(A, b, x_0,1.2,1)\n",
    "    i += 1    \n",
    "    forward_error = abs(x_0 - x_correct).max()\n",
    "    if forward_error <  1e-6:\n",
    "        break\n",
    "\n",
    "backward_error = abs(A.dot(x_0) - b).max()\n",
    "#GAUS\n",
    "print (\"SOR\")\n",
    "print(\"# of Steps - \", i)\n",
    "print(\"Backward error - \" , backward_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d096fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOR converges faster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f770b",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Solve the system $Hx = b$ by the Conjugate Gradient Method, where $H$ is the $n \\times n$ Hilbert matrix and $b$ is the vector of all ones, for \n",
    "\n",
    "(a) $n = 4$\n",
    "\n",
    "(b) $n = 8$.\n",
    "\n",
    "What can you say about the solutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dab3142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=4\n",
      "[0.6 0.8 0.8 0.6]\n"
     ]
    }
   ],
   "source": [
    "# Conjugate Gradient Method\n",
    "def ConjGrad_v1(A, b, x0, eps):\n",
    "    \"\"\"\n",
    "    Perform conjugate gradient method, the first version.\n",
    "    A: a symmetric positive definite matrix\n",
    "    b: the right-hand side\n",
    "    x0: the initial guess\n",
    "    eps: the tolerance for stopping the algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    if not np.array_equal(A.T, A):\n",
    "        print('Error: the matrix A is not symmetric!')\n",
    "        return\n",
    "        \n",
    "    n = A.shape[0]\n",
    "    r = np.zeros((n,n+1)) # The ith column stores r_i  \n",
    "    u = np.zeros((n,n+1)) # The ith column stores u_i\n",
    "    r[:,0] = b-np.dot(A, x0)\n",
    "    if np.linalg.norm(r) < eps:\n",
    "        return x0\n",
    "    u[:,0] = r[:,0]\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for k in range(n):        \n",
    "        a = np.dot(u[:,k], r[:,k])/np.dot(u[:,k], np.dot(A,u[:,k]))\n",
    "        x += a*u[:,k]\n",
    "        r[:,k+1] = b - np.dot(A, x)\n",
    "        if np.linalg.norm(r) < eps:\n",
    "            return x\n",
    "        sum = np.zeros(n)\n",
    "        for i in range(k+1):\n",
    "            sum += np.dot(r[:,k+1], np.dot(A, u[:,i]))/np.dot(u[:,i], np.dot(A, u[:,i]))*u[:,i]\n",
    "        u[:,k+1] = r[:,k+1] - sum\n",
    "        \n",
    "    return x\n",
    "\n",
    "#n=4\n",
    "n = 4\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "x_0 = np.zeros(n)\n",
    "eps = 1e-6\n",
    "print(\"n=4\")\n",
    "print(ConjGrad_v1(A, b, x_0, eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89cd828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=8\n",
      "[0.61764706 0.85294118 0.94117647 0.97058824 0.97058824 0.94117647\n",
      " 0.85294118 0.61764706]\n"
     ]
    }
   ],
   "source": [
    "#n=8\n",
    "n = 8\n",
    "#init vals\n",
    "A = matrix(n)\n",
    "b = np.ones(n)\n",
    "x_0 = np.zeros(n)\n",
    "eps = 1e-6\n",
    "print(\"n=8\")\n",
    "print(ConjGrad_v1(A, b, x_0, eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2606dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the value of n increases, the point accuracy of the solution becomes greater. Also the first 2 elements and last 2 elements\n",
    "# are similar for both n=4 and n=8 except the precision of decimal accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c3d41",
   "metadata": {},
   "source": [
    "# Problem 4 (MATH 5660 ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4dcb4",
   "metadata": {},
   "source": [
    "Convergence of iterative methods like the Conjugate Gradient Method can be accelerated\n",
    "by the use of a technique called **preconditioning**. The convergence rates of iterative\n",
    "methods often depend, directly or indirectly, on the condition number of the\n",
    "coefficient matrix A. The idea of preconditioning is to reduce the effective condition\n",
    "number of the problem.\n",
    "\n",
    "The preconditioned form of the $n \\times n$ linear system $A\\boldsymbol{x} = \\boldsymbol{b}$ is\n",
    "$$\n",
    "M^{-1}A\\boldsymbol{x} = M^{-1}\\boldsymbol{b},\n",
    "$$\n",
    "where $M$ is an invertible $n \\times n$ matrix called the **preconditioner**.\n",
    "\n",
    "When $A$ is a symmetric positive-definite $n \\times n$ matrix, we will choose a symmetric\n",
    "positive-definite matrix $M$ for use as a preconditioner. A particularly simple choice is the **Jacobi preconditioner** $M = D$, where $D$ is the diagonal of $A$. The Preconditioned Conjugate Gradient\n",
    "Method is now easy to describe: Replace $A\\boldsymbol{x} = \\boldsymbol{b}$ with the preconditioned equation $M^{âˆ’1} A\\boldsymbol{x} = M^{âˆ’1}\\boldsymbol{b}$, and replace the Euclidean inner product with $(\\boldsymbol{v},\\boldsymbol{w})M$.\n",
    "\n",
    "To convert Algorithm 2 in Section 3.3 to the preconditioned version, let $\\boldsymbol{z}_k = M^{-1}\\boldsymbol{b} - M^{-1}A\\boldsymbol{x}_k = M^{-1}\\boldsymbol{r}_k$. Then the algorithm is\n",
    "\n",
    "1. Initialize $\\boldsymbol{x}_0$ as any vector. Set $\\boldsymbol{r}_0=\\boldsymbol{b}-A\\boldsymbol{x}_0$ and $\\boldsymbol{u}_0=\\boldsymbol{z}_0=M^{-1}\\boldsymbol{r}_0$.\n",
    "\n",
    "2. For $k=0, 1, \\dots, n-1$:\n",
    "\n",
    "    1. $a_k=\\frac{\\boldsymbol{r}_k^T \\boldsymbol{z}_k}{\\boldsymbol{u}_k^TA\\boldsymbol{u}_k}$\n",
    "    2. $\\boldsymbol{x}_{k+1} = \\boldsymbol{x}_k + a_k \\boldsymbol{u}_k$\n",
    "    3. $\\boldsymbol{r}_{k+1} = \\boldsymbol{r}_{k}-a_kA\\boldsymbol{u}_{k}$\n",
    "    4. if ($||\\boldsymbol{r}_{k+1}|| < \\epsilon$):\n",
    "        1. break\n",
    "    5. $\\boldsymbol{z}_{k+1} = M^{-1}\\boldsymbol{r}_{k+1}$\n",
    "    6. $\\boldsymbol{b}_k = \\frac{\\boldsymbol{r}_{k+1}^T\\boldsymbol{z}_{k+1}}{\\boldsymbol{r}_{k}^T\\boldsymbol{z}_{k}}$\n",
    "    7. $\\boldsymbol{u}_{k+1} = \\boldsymbol{z}_{k+1} + \\boldsymbol{b}_k\\boldsymbol{u}_{k}$\n",
    "\n",
    "3. return $\\boldsymbol{x}_{k+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926388d1",
   "metadata": {},
   "source": [
    "Now, consider the following problem.\n",
    "\n",
    "Let $A$ be the $n \\times n$ matrix with $n = 1000$ and entries $A(i, i) = i$, $A(i, i+1) = A(i+1, i) = 1/2$, $A(i, i + 2) = A(i + 2, i ) = 1/2$ for all $i$ that fit\n",
    "within the matrix. \n",
    "\n",
    "(a) Take a look at the nonzero structure of the matrix using plt.spy(A). \n",
    "\n",
    "(b) Let $\\boldsymbol{x}_e$ be the vector of $n$ ones (exact solution). Set $\\boldsymbol{b} = A\\boldsymbol{x}_e$, and apply the Conjugate Gradient Method, without preconditioner, and\n",
    "with the Jacobi preconditioner. Compare errors (using 2-norm) of the two runs in a plot versus step number (using semilogy). (So you need to modify the conjugate gradient codes to keep track of and return the solutions of all steps.) Use eps = 1e-10. \n",
    "\n",
    "The two methods may converge in different number of steps. Which one do you see is faster?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
